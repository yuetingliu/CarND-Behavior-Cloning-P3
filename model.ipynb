{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function for loading images and steering angles\n",
    "def preprocess_img(image):\n",
    "    # Crop the top 50 pixes\n",
    "    img = image[50:, :, :]\n",
    "    # Resize to 200*66\n",
    "    img = cv2.resize(img, (200, 66))\n",
    "    return img\n",
    "\n",
    "def load_data(data):\n",
    "    '''\n",
    "    Get the images and the steering angles\n",
    "    Params:\n",
    "    data: the folder where images and logfile are stored\n",
    "    The the first line of the logfile consists of names. All the rest lines consist of the locations of images, \n",
    "    steering angles, and other data. To load the images and steering angles, the first line is omitted.\n",
    "    '''\n",
    "    images = []\n",
    "    steers = []\n",
    "    loc = data + '/driving_log.csv'\n",
    "    with open(loc) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        i = 0 # This count is for omitting the first line of the logfile\n",
    "        for line in reader:\n",
    "        # Skip the header \n",
    "            if i > 0:\n",
    "                # First, get the image name for the middle, left, right cameras\n",
    "                path_mid = line[0].split('/')[-1]\n",
    "                path_left = line[1].split('/')[-1]\n",
    "                path_right = line[2].split('/')[-1]\n",
    "                # Second, get the image path\n",
    "                img_path_mid = data + '/IMG/' + path_mid\n",
    "                img_path_left = data + '/IMG/' + path_left\n",
    "                img_path_right = data + '/IMG/' + path_right\n",
    "                # Third, load the images \n",
    "                # cv2 loads images as BGR, convert to RGB\n",
    "                img = cv2.imread(img_path_mid)[:, :, ::-1]\n",
    "                img = preprocess_img(img)\n",
    "                img_left = cv2.imread(img_path_left)[:, :, ::-1]\n",
    "                img_left = preprocess_img(img_left)\n",
    "                img_right = cv2.imread(img_path_right)[:, :, ::-1]\n",
    "                img_right = preprocess_img(img_right)\n",
    "                # Finally, append all images and corresponding steering angles into lists. \n",
    "                # Left and right camera images are there for steering cars to the middle, 0.5 is chosen for correction\n",
    "                images.append(img)\n",
    "                steers.append(float(line[3]))\n",
    "                images.append(img_left)\n",
    "                steers.append(0.75)\n",
    "                images.append(img_right)\n",
    "                steers.append(-0.75)\n",
    "                # Flip the middle images \n",
    "                img2 = np.fliplr(img)\n",
    "                images.append(img2)\n",
    "                steers.append(-float(line[3]))\n",
    "            i += 1\n",
    "    return images, steers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle the images and split into training and validation sets\n",
    "def train_valid_split(images, steers, valid_size = 0.05):\n",
    "    ind = np.arange(len(images))\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(ind)\n",
    "    cutoff = int(len(ind)*(1-valid_size))\n",
    "    train_ind = ind[:cutoff]\n",
    "    valid_ind = ind[cutoff:]\n",
    "    train_images = [images[i] for i in train_ind]\n",
    "    valid_images = [images[i] for i in valid_ind]\n",
    "    train_steers = [steers[i] for i in train_ind]\n",
    "    valid_steers = [steers[i] for i in valid_ind]\n",
    "    return train_images, train_steers, valid_images, valid_steers\n",
    "\n",
    "# Define a generator for memory saving. Put the generator into a while loop to avoid running out of data during training\n",
    "def generator_(X, y, batch_size = 64):\n",
    "    while True:\n",
    "        for offset in range(0, len(X), batch_size):\n",
    "            end = offset + batch_size\n",
    "            X_batch = np.array(X[offset:end])\n",
    "            y_batch = np.array(y[offset:end])\n",
    "            yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_data(images, steers, nb_bins=30, cutoff=2000):\n",
    "    \"\"\"Make the training data distribution less steep by discarding some data\n",
    "    \n",
    "    Params: \n",
    "    nb_bins: the number of bins for counting steers angles\n",
    "    cutoff: the value threshold, if a steering angle has more samples than it, then remove part of the data\n",
    "    \n",
    "    Return: trimmed images and steering angles\n",
    "    \"\"\"\n",
    "    hist, bins = np.histogram(steers, bins=np.linspace(-1,1, nb_bins))\n",
    "    # Find the bins that need to discard some data\n",
    "    bin_ind_to_remove = [i for i in range(len(hist)) if hist[i]>cutoff]\n",
    "\n",
    "    # Calculate the probability to keep for the selected bins. \n",
    "    # The prob equals the average adjacent bin counts divided by the real counts of the bin\n",
    "    keep_prob = [(hist[i-1]+hist[i+1])/(2*hist[i]) for i in bin_ind_to_remove]\n",
    "\n",
    "    # Create an index for data deletion\n",
    "    index2delete = []\n",
    "    for i in range(len(steers)):\n",
    "        for j in bin_ind_to_remove:\n",
    "            if steers[i] > bins[j] and steers[i] <= bins[j+1]:\n",
    "                if np.random.random() > keep_prob[bin_ind_to_remove.index(j)]:\n",
    "                    index2delete.append(i)\n",
    "    images = [images[i] for i in range(len(images)) if i not in index2delete]\n",
    "    steers = [steers[i] for i in range(len(steers)) if i not in index2delete]\n",
    "#     print('{} hist in {} bins'.format(len(hist), len(bins)))\n",
    "#     print('')\n",
    "#     print('The trimmed steering angles are in bins: {}'.format([(bins[i], bins[i+1]) for i in bin_ind_to_remove]),\n",
    "#           'The respective keep probabilities are: {}'.format(keep_prob))\n",
    "    return images, steers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the images and steering angle data\n",
    "images, steers = [], []\n",
    "for data in ['./data', './data2', './data3']:\n",
    "    image, steer = load_data(data)\n",
    "    images.extend(image)\n",
    "    steers.extend(steer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 hist in 30 bins\n",
      "\n",
      "The trimmed steering angles are in bins: [(-0.7931034482758621, -0.72413793103448276), (-0.034482758620689724, 0.034482758620689724), (0.72413793103448265, 0.7931034482758621)] The respective keep probabilities are: [0.0034687809712586719, 0.043366224624473634, 0.0034687809712586719]\n"
     ]
    }
   ],
   "source": [
    "trimmed_images, trimmed_steers = trim_data(images, steers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAADGCAYAAAAg5qKlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7JIkdcj/B1Bfoohmryw8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f88707ab080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "axes[0].hist(steers, bins=30)\n",
    "axes[1].hist(trimmed_steers,bins=30)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "# plt.ylim(0, 2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_images, train_steers, valid_images, valid_steers = train_valid_split(trimmed_images, trimmed_steers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers import Convolution2D, Lambda, Cropping2D\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13091/13091 [==============================] - 12s - loss: 0.0915 - val_loss: 0.0602\n",
      "Epoch 2/10\n",
      "13091/13091 [==============================] - 11s - loss: 0.0676 - val_loss: 0.0544\n",
      "Epoch 3/10\n",
      "13091/13091 [==============================] - 11s - loss: 0.0610 - val_loss: 0.0535\n",
      "Epoch 4/10\n",
      "13091/13091 [==============================] - 11s - loss: 0.0561 - val_loss: 0.0517\n",
      "Epoch 5/10\n",
      "13091/13091 [==============================] - 11s - loss: 0.0535 - val_loss: 0.0510\n",
      "Epoch 6/10\n",
      "13091/13091 [==============================] - 11s - loss: 0.0511 - val_loss: 0.0487\n",
      "Epoch 7/10\n",
      "13091/13091 [==============================] - 11s - loss: 0.0490 - val_loss: 0.0480\n",
      "Epoch 8/10\n",
      "13091/13091 [==============================] - 11s - loss: 0.0473 - val_loss: 0.0474\n",
      "Epoch 9/10\n",
      "13091/13091 [==============================] - 11s - loss: 0.0453 - val_loss: 0.0482\n",
      "Epoch 10/10\n",
      "13091/13091 [==============================] - 11s - loss: 0.0446 - val_loss: 0.0471\n"
     ]
    }
   ],
   "source": [
    "# The model is similar with the model from Nvidia paper: Nvidia_X End-to-End Deep Learning for Self-Driving Cars\n",
    "model = Sequential()\n",
    "\n",
    "#input image size is 160*320*3\n",
    "model.add(Lambda(lambda x: x/127.5-1, input_shape=images[0].shape))\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2,2), border_mode='valid', activation='elu'))\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2,2), border_mode='valid', activation='elu'))\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2,2), border_mode='valid', activation='elu'))\n",
    "model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
    "model.add(Convolution2D(64, 3, 3, activation='elu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='elu'))\n",
    "model.add(Dense(50, activation='elu'))\n",
    "model.add(Dense(10, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer=keras.optimizers.adam(lr=0.0001))\n",
    "hist = model.fit_generator(generator_(train_images, train_steers), samples_per_epoch=len(train_images), \n",
    "       validation_data = generator_(valid_images, valid_steers), nb_val_samples = len(valid_images), nb_epoch=10)\n",
    "model.save('model.h5')\n",
    "with open('./model.json' ,'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
